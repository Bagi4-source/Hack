{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bagi4-source/Hack/blob/main/PyCaret_Classification_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подключаем библиотеки"
      ],
      "metadata": {
        "id": "2T7uFwa-KZAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import interpolate\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jW3is0pTKCUV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Реализация функциий чтения/записи данных"
      ],
      "metadata": {
        "id": "WKbu8jaDKkcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def import_dataset_from_file(path_to_file: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Функция импортирования исходных данных.\n",
        "    :param path_to_file: путь к загружаемому файлу;\n",
        "    :return: структура данных.\n",
        "    \"\"\"\n",
        "    dataset = pd.read_table(path_to_file, delim_whitespace=True, names=['x', 'y', 'z'])\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "yBio4BR2KFZl"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_dataset_to_file(dataset: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Функция экспортирования результата в файл result.txt.\n",
        "    :param dataset: входная структура данных.\n",
        "    \"\"\"\n",
        "    n, c = dataset.shape\n",
        "\n",
        "    assert c == 3, 'Количество столбцов должно быть 3'\n",
        "    assert n == 1196590, 'Количество строк должно быть 1196590'\n",
        "\n",
        "    with open('Data\\\\Result.txt', 'w') as f:\n",
        "        for i in range(n):\n",
        "            f.write('%.2f %.2f %.5f\\n' % (dataset.x[i], dataset.y[i], dataset.z[i]))"
      ],
      "metadata": {
        "id": "Z0GboSOiKJQI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Чтение всех данных"
      ],
      "metadata": {
        "id": "ZvSy6-yuKspF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вспомогательные данные, по которым производится моделирование\n",
        "map_1_dataset = import_dataset_from_file(\"/content/sample_data/Map_1.txt\")\n",
        "map_2_dataset = import_dataset_from_file(\"/content/sample_data/Map_2.txt\")\n",
        "map_3_dataset = import_dataset_from_file(\"/content/sample_data/Map_3.txt\")\n",
        "map_4_dataset = import_dataset_from_file(\"/content/sample_data/Map_4.txt\")\n",
        "map_5_dataset = import_dataset_from_file(\"/content/sample_data/Map_5.txt\")\n",
        "\n",
        "# Данные, по которым необходимо смоделировать\n",
        "point_dataset = import_dataset_from_file(\"/content/sample_data/Point_dataset.txt\")\n",
        "\n",
        "# Точки данных, в которые необходимо провести моделирование (сетка данных)\n",
        "point_grid = import_dataset_from_file(\"/content/sample_data/Result_schedule.txt\")"
      ],
      "metadata": {
        "id": "-f9YIgStKKmS"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Реализация"
      ],
      "metadata": {
        "id": "5OPhg9DrK4Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fqAR1lMyK3Fo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}